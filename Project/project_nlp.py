# -*- coding: utf-8 -*-
"""Project_NLP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1v326SlO9EWi3vjy3fKcQ-vdIYgWt8mVG

# **Reynara Ezra Pratama**
"""

import tensorflow as tf
print(tf.__version__)

# Commented out IPython magic to ensure Python compatibility.
!pip install ipython-autotime
# %load_ext autotime

import pandas as pd

df = pd.read_csv('/content/emotion.txt', names = ['sentence', 'emote'], sep=';')

df.head()

df.tail()

df.sample(5)

print('Number of Data:',len(df))

df['emote'].value_counts()

category = pd.get_dummies(df['emote'])
category.head()

df = df.drop('emote', axis=1)

df_new = pd.concat([df, category], axis=1)
df_new.head()

df_new.tail()

text = df_new['sentence'].values
emote = df_new[['anger', 'fear', 'joy', 'love', 'sadness', 'surprise']].values

text

emote

from sklearn.model_selection import train_test_split

text_train, text_test, emote_train, emote_test = train_test_split(
    text,
    emote,
    test_size=0.2,
    random_state=0
)

from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

tokenizer = Tokenizer(num_words=20000, oov_token='-')
tokenizer.fit_on_texts(text_train)
tokenizer.fit_on_texts(text_test)

sequence_train = tokenizer.texts_to_sequences(text_train)
sequence_test = tokenizer.texts_to_sequences(text_test)

pad_train = pad_sequences(sequence_train)
pad_test = pad_sequences(sequence_test)

reduce_LR = tf.keras.callbacks.ReduceLROnPlateau(
    monitor="val_loss",
    factor=0.15,
    patience=5,
    min_lr=2.e-5
)

stop_early = tf.keras.callbacks.EarlyStopping(
    monitor="val_loss",
    min_delta=0,
    patience=10,
    verbose=0,
    mode="auto",
    baseline=None,
    restore_best_weights=True
)

model = tf.keras.models.Sequential([
   tf.keras.layers.Embedding(input_dim=20000, output_dim=64),
   tf.keras.layers.Dropout(0.4),
   tf.keras.layers.LSTM(64),
   tf.keras.layers.Dropout(0.3),
   tf.keras.layers.Dense(64, activation='relu'),
   tf.keras.layers.Dropout(0.2),
   tf.keras.layers.Dense(64, activation='relu'),
   tf.keras.layers.Dense(6, activation='softmax')
])

model.summary()

model.compile(
    optimizer='Adam',
    loss = 'categorical_crossentropy',
    metrics = ['accuracy']
)

history = model.fit(
    pad_train,
    emote_train,
    epochs = 100,
    callbacks = [reduce_LR, stop_early],
    validation_data = (pad_test, emote_test),
    verbose = 1
)

import matplotlib.pyplot as plt

def plot_accuracy(history):
  plt.figure(figsize=(18,5))
  acc = history.history['accuracy']
  val_acc = history.history['val_accuracy']
  epochs = range(len(acc))
  plot_acc = plt.plot(epochs, acc, 'red', label='Training Accuracy')
  plot_val_acc = plt.plot(epochs, val_acc, 'blue', label='Validation Accuracy')
  plt.xlabel('Epoch', fontsize=15)
  plt.ylabel('Accuracy', fontsize=15)
  plt.title('Training and Validation Accuracy', fontsize=25)
  plt.legend(bbox_to_anchor=(1,1), loc='best')
  plt.grid()
  plt.show()

def plot_loss(history):
  plt.figure(figsize=(18,5))
  loss = history.history['loss']
  val_loss = history.history['val_loss']
  epochs = range(len(loss))
  plot_loss = plt.plot(epochs, loss, 'red', label='Training Loss')
  plot_val_loss = plt.plot(epochs, val_loss, 'blue', label='Validation Loss')
  plt.xlabel('Epoch', fontsize=15)
  plt.ylabel('Loss', fontsize=15)
  plt.title('Training and Validation Loss', fontsize=25)
  plt.legend(bbox_to_anchor=(1,1), loc='best')
  plt.grid()
  plt.show()

plot_accuracy(history)

plot_loss(history)

converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

with tf.io.gfile.GFile('model.tflite', 'wb') as f:
  f.write(tflite_model)

def predict_sentence(sentence, model=model):
  seq = tokenizer.texts_to_sequences([sentence])
  pad = pad_sequences(seq)
  predict_array = model.predict(pad)[0]
  maks = max(predict_array)

  for i in range(len(predict_array)):
    if predict_array[i] == maks:
      index = i
      break

  if index == 0:
    predict_label = "Anger"
  elif index == 1:
    predict_label = "Fear"
  elif index == 2:
    predict_label = "Joy"
  elif index == 3:
    predict_label = "Love"
  elif index == 4:
    predict_label = "Sadness"
  else:
    predict_label = "Surprise"

  dff = pd.DataFrame()
  dff['Emotion'] = ['Anger', 'Fear', 'Joy', 'Love', 'Sadness', 'Surprise']
  dff['Probability'] = predict_array

  return predict_label, dff

sentence = "I graduated from the Bandung Institute of Technology"

label, prob = predict_sentence(sentence)

print("The sentence is detected as :", label)
print(prob)

sentence1 = "I was sad when I failed to enter the Bandung Institute of Technology"

label1, prob1 = predict_sentence(sentence1)

print("The sentence is detected as :", label1)
print(prob1)